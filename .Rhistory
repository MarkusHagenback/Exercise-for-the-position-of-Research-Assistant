##   Reading in the data from Github   ##
#########################################
# This approach makes it possible to only need this R-script to read the entire code
# Thus, no need to copy the data-files etc.
library(readxl) # Library needed to read in the file correctly
# URL of the raw file
url <- "https://raw.githubusercontent.com/MarkusHagenback/Exercise-for-the-position-of-Research-Assistant/main/exercise.xlsx"
temp_file <- tempfile(fileext = ".xlsx") #Create a temporary file to store the downloaded Excel file
# Download the Excel file to the temporary location
download.file(url, destfile = temp_file, mode = "wb")
# Read the Excel file into R
data <- read_excel(temp_file)
# Delete the temporary file after use
rm(temp_file)
rm(url)
################################################################################
#   Data cleaning
################################################################################
# Making date column as.date
data$date <- as.Date(data$date, format = "%Y-%m-%d")  # Adjust format if needed
#############################################
# Rating column has some non-numeric values #
#############################################
#Will remove these ones (later), as they do not contain any information
# Identify rows where 'average rating' is non-numeric
troublesome_rows_non_numeric <- which(!grepl("^\\d+(\\.\\d+)?$", data$`average rating`)) # Will remove later
# Converting to numeric
data$`average rating` <- as.numeric(data$`average rating`)
################
# NA questions #
################
# Will be removed, as these contains little information
# Identify rows where 'question' is NA
troublesome_rows_question <- which(is.na(data$question))
########################
# Question topic is NA #
########################
# Based on the information from other rows, we know what it should be
# Identify rows where 'question topic' is NA
na_question_topic <- which(is.na(data$`question topic`))
# For each row with NA in 'question topic', find the corresponding value from other rows with the same 'question'
for (i in na_question_topic) {
# Find the 'question' value for the current row with NA
question_value <- data$question[i]
# Find the most common 'question topic' for rows with the same 'question'
# Filter rows where 'question' matches and exclude NA 'question topic'
matching_rows <- data[data$question == question_value & !is.na(data$`question topic`), ]
if (nrow(matching_rows) > 0) {
# Use the most frequent 'question topic' from matching rows
most_common_topic <- names(sort(table(matching_rows$`question topic`), decreasing = TRUE))[1]
data$`question topic`[i] <- most_common_topic
}
}
########################
# Wrong question topic #
########################
# Create a lookup table for the most common 'question topic' for each 'question'
most_common_topics <- aggregate(`question topic` ~ question, data = data, function(x) {
names(sort(table(x), decreasing = TRUE))[1]
})
# Convert to a named vector for easier lookup
common_topic_lookup <- setNames(most_common_topics$`question topic`, most_common_topics$question)
# Vector to store row numbers where updates are made
troublesome_rows_wrong_topic <- integer(0)
# Update rows where 'question topic' is different from the majority
for (i in seq_len(nrow(data))) {
# Skip the row if 'question topic' or 'question' is NA (these are already fixed)
if (is.na(data$`question topic`[i]) || is.na(data$question[i])) {
next
}
question_value <- data$question[i]
# Determine the correct 'question topic' from the lookup table
correct_topic <- common_topic_lookup[question_value]
if (data$`question topic`[i] != correct_topic) {
# Save the row number where the update happens
troublesome_rows_wrong_topic <- c(troublesome_rows_wrong_topic, i)
# Update 'question topic' to the most common topic
data$`question topic`[i] <- correct_topic
}
}
##############################
# Creating a dataframe/table #
##############################
# For what we have done with the data, for the report
# Create individual dataframes for each list with explanations
df_na_question_topic <- data.frame(
RowNumber = na_question_topic,
Explanation = "NA question topic (Updated)"
)
df_wrong_topic <- data.frame(
RowNumber = troublesome_rows_wrong_topic,
Explanation = "Wrong question topic (Updated)"
)
df_non_numeric <- data.frame(
RowNumber = troublesome_rows_non_numeric,
Explanation = "Non numeric value in average rating (Removed)"
)
df_na_question <- data.frame(
RowNumber = troublesome_rows_question,
Explanation = "NA questions (Removed)"
)
# Combine all dataframes into one
df_combined <- rbind(df_na_question_topic, df_wrong_topic, df_non_numeric, df_na_question)
# Some rows needs to be removed, insufficient data to analyse
troublesome_rows_to_remove <- unique(c(troublesome_rows_non_numeric, troublesome_rows_question))
# Removing these troublesome rows
data <- data[-troublesome_rows_to_remove, ]
# Finally, there is some missing values for the other columns.
# However, it is still okay to use those rows for analysis.
# As these rows still contains information that is valuable.
# For instance, even if we don't know the sponsor organisation,
# we can still use the row to analyse virtual classes
################################################################################
#   End of data cleaning
################################################################################
all_objects <- ls()
rm(list=ls()) # Removes everything from the work environment
#########################################
##   Reading in the data from Github   ##
#########################################
# This approach makes it possible to only need this R-script to read the entire code
# Thus, no need to copy the data-files etc.
library(readxl) # Library needed to read in the file correctly
# URL of the raw file
url <- "https://raw.githubusercontent.com/MarkusHagenback/Exercise-for-the-position-of-Research-Assistant/main/exercise.xlsx"
temp_file <- tempfile(fileext = ".xlsx") #Create a temporary file to store the downloaded Excel file
# Download the Excel file to the temporary location
download.file(url, destfile = temp_file, mode = "wb")
# Read the Excel file into R
data <- read_excel(temp_file)
# Delete the temporary file after use
rm(temp_file)
rm(url)
################################################################################
#   Data cleaning
################################################################################
# Making date column as.date
data$date <- as.Date(data$date, format = "%Y-%m-%d")  # Adjust format if needed
#############################################
# Rating column has some non-numeric values #
#############################################
#Will remove these ones (later), as they do not contain any information
# Identify rows where 'average rating' is non-numeric
troublesome_rows_non_numeric <- which(!grepl("^\\d+(\\.\\d+)?$", data$`average rating`)) # Will remove later
# Converting to numeric
data$`average rating` <- as.numeric(data$`average rating`)
################
# NA questions #
################
# Will be removed, as these contains little information
# Identify rows where 'question' is NA
troublesome_rows_question <- which(is.na(data$question))
########################
# Question topic is NA #
########################
# Based on the information from other rows, we know what it should be
# Identify rows where 'question topic' is NA
na_question_topic <- which(is.na(data$`question topic`))
# For each row with NA in 'question topic', find the corresponding value from other rows with the same 'question'
for (i in na_question_topic) {
# Find the 'question' value for the current row with NA
question_value <- data$question[i]
# Find the most common 'question topic' for rows with the same 'question'
# Filter rows where 'question' matches and exclude NA 'question topic'
matching_rows <- data[data$question == question_value & !is.na(data$`question topic`), ]
if (nrow(matching_rows) > 0) {
# Use the most frequent 'question topic' from matching rows
most_common_topic <- names(sort(table(matching_rows$`question topic`), decreasing = TRUE))[1]
data$`question topic`[i] <- most_common_topic
}
}
########################
# Wrong question topic #
########################
# Create a lookup table for the most common 'question topic' for each 'question'
most_common_topics <- aggregate(`question topic` ~ question, data = data, function(x) {
names(sort(table(x), decreasing = TRUE))[1]
})
# Convert to a named vector for easier lookup
common_topic_lookup <- setNames(most_common_topics$`question topic`, most_common_topics$question)
# Vector to store row numbers where updates are made
troublesome_rows_wrong_topic <- integer(0)
# Update rows where 'question topic' is different from the majority
for (i in seq_len(nrow(data))) {
# Skip the row if 'question topic' or 'question' is NA (these are already fixed)
if (is.na(data$`question topic`[i]) || is.na(data$question[i])) {
next
}
question_value <- data$question[i]
# Determine the correct 'question topic' from the lookup table
correct_topic <- common_topic_lookup[question_value]
if (data$`question topic`[i] != correct_topic) {
# Save the row number where the update happens
troublesome_rows_wrong_topic <- c(troublesome_rows_wrong_topic, i)
# Update 'question topic' to the most common topic
data$`question topic`[i] <- correct_topic
}
}
##############################
# Creating a dataframe/table #
##############################
# For what we have done with the data, for the report
# Create individual dataframes for each list with explanations
df_na_question_topic <- data.frame(
RowNumber = na_question_topic,
Explanation = "NA question topic (Updated)"
)
df_wrong_topic <- data.frame(
RowNumber = troublesome_rows_wrong_topic,
Explanation = "Wrong question topic (Updated)"
)
df_non_numeric <- data.frame(
RowNumber = troublesome_rows_non_numeric,
Explanation = "Non numeric value in average rating (Removed)"
)
df_na_question <- data.frame(
RowNumber = troublesome_rows_question,
Explanation = "NA questions (Removed)"
)
# Combine all dataframes into one
data_cleaning_table <- rbind(df_na_question_topic, df_wrong_topic, df_non_numeric, df_na_question)
# Some rows needs to be removed, insufficient data to analyse
troublesome_rows_to_remove <- unique(c(troublesome_rows_non_numeric, troublesome_rows_question))
# Removing these troublesome rows
data <- data[-troublesome_rows_to_remove, ]
# Finally, there is some missing values for the other columns.
# However, it is still okay to use those rows for analysis.
# As these rows still contains information that is valuable.
# For instance, even if we don't know the sponsor organisation,
# we can still use the row to analyse virtual classes
################################################################################
objects_to_keep
objects_to_keep <- c("data", "data_cleaning_table")
all_objects <- ls()
all_objects
objects_to_remove <- setdiff(all_objects, objects_to_keep)
objects_to_remove
rm(list = objects_to_remove)
rm(all_objects)
rm(objects_to_remove)
rm(list=ls()) # Removes everything from the work environment
#########################################
##   Reading in the data from Github   ##
#########################################
# This approach makes it possible to only need this R-script to read the entire code
# Thus, no need to copy the data-files etc.
library(readxl) # Library needed to read in the file correctly
# URL of the raw file
url <- "https://raw.githubusercontent.com/MarkusHagenback/Exercise-for-the-position-of-Research-Assistant/main/exercise.xlsx"
temp_file <- tempfile(fileext = ".xlsx") #Create a temporary file to store the downloaded Excel file
# Download the Excel file to the temporary location
download.file(url, destfile = temp_file, mode = "wb")
# Read the Excel file into R
data <- read_excel(temp_file)
# Delete the temporary file after use
rm(temp_file)
rm(url)
################################################################################
#   Data cleaning
################################################################################
# Making date column as.date
data$date <- as.Date(data$date, format = "%Y-%m-%d")  # Adjust format if needed
#############################################
# Rating column has some non-numeric values #
#############################################
#Will remove these ones (later), as they do not contain any information
# Identify rows where 'average rating' is non-numeric
troublesome_rows_non_numeric <- which(!grepl("^\\d+(\\.\\d+)?$", data$`average rating`)) # Will remove later
# Converting to numeric
data$`average rating` <- as.numeric(data$`average rating`)
################
# NA questions #
################
# Will be removed, as these contains little information
# Identify rows where 'question' is NA
troublesome_rows_question <- which(is.na(data$question))
########################
# Question topic is NA #
########################
# Based on the information from other rows, we know what it should be
# Identify rows where 'question topic' is NA
na_question_topic <- which(is.na(data$`question topic`))
# For each row with NA in 'question topic', find the corresponding value from other rows with the same 'question'
for (i in na_question_topic) {
# Find the 'question' value for the current row with NA
question_value <- data$question[i]
# Find the most common 'question topic' for rows with the same 'question'
# Filter rows where 'question' matches and exclude NA 'question topic'
matching_rows <- data[data$question == question_value & !is.na(data$`question topic`), ]
if (nrow(matching_rows) > 0) {
# Use the most frequent 'question topic' from matching rows
most_common_topic <- names(sort(table(matching_rows$`question topic`), decreasing = TRUE))[1]
data$`question topic`[i] <- most_common_topic
}
}
########################
# Wrong question topic #
########################
# Create a lookup table for the most common 'question topic' for each 'question'
most_common_topics <- aggregate(`question topic` ~ question, data = data, function(x) {
names(sort(table(x), decreasing = TRUE))[1]
})
# Convert to a named vector for easier lookup
common_topic_lookup <- setNames(most_common_topics$`question topic`, most_common_topics$question)
# Vector to store row numbers where updates are made
troublesome_rows_wrong_topic <- integer(0)
# Update rows where 'question topic' is different from the majority
for (i in seq_len(nrow(data))) {
# Skip the row if 'question topic' or 'question' is NA (these are already fixed)
if (is.na(data$`question topic`[i]) || is.na(data$question[i])) {
next
}
question_value <- data$question[i]
# Determine the correct 'question topic' from the lookup table
correct_topic <- common_topic_lookup[question_value]
if (data$`question topic`[i] != correct_topic) {
# Save the row number where the update happens
troublesome_rows_wrong_topic <- c(troublesome_rows_wrong_topic, i)
# Update 'question topic' to the most common topic
data$`question topic`[i] <- correct_topic
}
}
##############################
# Creating a dataframe/table #
##############################
# For what we have done with the data, for the report
# Create individual dataframes for each list with explanations
df_na_question_topic <- data.frame(
RowNumber = na_question_topic,
Explanation = "NA question topic (Updated)"
)
df_wrong_topic <- data.frame(
RowNumber = troublesome_rows_wrong_topic,
Explanation = "Wrong question topic (Updated)"
)
df_non_numeric <- data.frame(
RowNumber = troublesome_rows_non_numeric,
Explanation = "Non numeric value in average rating (Removed)"
)
df_na_question <- data.frame(
RowNumber = troublesome_rows_question,
Explanation = "NA questions (Removed)"
)
# Combine all dataframes into one
data_cleaning_table <- rbind(df_na_question_topic, df_wrong_topic, df_non_numeric, df_na_question)
# Some rows needs to be removed, insufficient data to analyse
troublesome_rows_to_remove <- unique(c(troublesome_rows_non_numeric, troublesome_rows_question))
# Removing these troublesome rows
data <- data[-troublesome_rows_to_remove, ]
# Finally, there is some missing values for the other columns.
# However, it is still okay to use those rows for analysis.
# As these rows still contains information that is valuable.
# For instance, even if we don't know the sponsor organisation,
# we can still use the row to analyse virtual classes
################################################################################
#                     Cleaning up the environment
# Define the objects to keep
objects_to_keep <- c("data", "data_cleaning_table")
# Get a list of all objects in the environment
all_objects <- ls()
# Identify objects to remove (those not in the list of objects to keep)
objects_to_remove <- setdiff(all_objects, objects_to_keep)
# Remove the objects that are not in the keep list
rm(list = objects_to_remove)
rm(all_objects)
rm(objects_to_remove)
################################################################################
#   End of data cleaning
################################################################################
View(data_cleaning_table)
rm(list=ls()) # Removes everything from the work environment
#########################################
##   Reading in the data from Github   ##
#########################################
# This approach makes it possible to only need this R-script to read the entire code
# Thus, no need to copy the data-files etc.
library(readxl) # Library needed to read in the file correctly
# URL of the raw file
url <- "https://raw.githubusercontent.com/MarkusHagenback/Exercise-for-the-position-of-Research-Assistant/main/exercise.xlsx"
temp_file <- tempfile(fileext = ".xlsx") #Create a temporary file to store the downloaded Excel file
# Download the Excel file to the temporary location
download.file(url, destfile = temp_file, mode = "wb")
# Read the Excel file into R
data <- read_excel(temp_file)
# Delete the temporary file after use
rm(temp_file)
rm(url)
################################################################################
#   Data cleaning
################################################################################
# Making date column as.date
data$date <- as.Date(data$date, format = "%Y-%m-%d")  # Adjust format if needed
#############################################
# Rating column has some non-numeric values #
#############################################
#Will remove these ones (later), as they do not contain any information
# Identify rows where 'average rating' is non-numeric
troublesome_rows_non_numeric <- which(!grepl("^\\d+(\\.\\d+)?$", data$`average rating`)) # Will remove later
# Converting to numeric
data$`average rating` <- as.numeric(data$`average rating`)
################
# NA questions #
################
# Will be removed, as these contains little information
# Identify rows where 'question' is NA
troublesome_rows_question <- which(is.na(data$question))
########################
# Question topic is NA #
########################
# Based on the information from other rows, we know what it should be
# Identify rows where 'question topic' is NA
na_question_topic <- which(is.na(data$`question topic`))
# For each row with NA in 'question topic', find the corresponding value from other rows with the same 'question'
for (i in na_question_topic) {
# Find the 'question' value for the current row with NA
question_value <- data$question[i]
# Find the most common 'question topic' for rows with the same 'question'
# Filter rows where 'question' matches and exclude NA 'question topic'
matching_rows <- data[data$question == question_value & !is.na(data$`question topic`), ]
if (nrow(matching_rows) > 0) {
# Use the most frequent 'question topic' from matching rows
most_common_topic <- names(sort(table(matching_rows$`question topic`), decreasing = TRUE))[1]
data$`question topic`[i] <- most_common_topic
}
}
########################
# Wrong question topic #
########################
# Create a lookup table for the most common 'question topic' for each 'question'
most_common_topics <- aggregate(`question topic` ~ question, data = data, function(x) {
names(sort(table(x), decreasing = TRUE))[1]
})
# Convert to a named vector for easier lookup
common_topic_lookup <- setNames(most_common_topics$`question topic`, most_common_topics$question)
# Vector to store row numbers where updates are made
troublesome_rows_wrong_topic <- integer(0)
# Update rows where 'question topic' is different from the majority
for (i in seq_len(nrow(data))) {
# Skip the row if 'question topic' or 'question' is NA (these are already fixed)
if (is.na(data$`question topic`[i]) || is.na(data$question[i])) {
next
}
question_value <- data$question[i]
# Determine the correct 'question topic' from the lookup table
correct_topic <- common_topic_lookup[question_value]
if (data$`question topic`[i] != correct_topic) {
# Save the row number where the update happens
troublesome_rows_wrong_topic <- c(troublesome_rows_wrong_topic, i)
# Update 'question topic' to the most common topic
data$`question topic`[i] <- correct_topic
}
}
##############################
# Creating a dataframe/table #
##############################
# For what we have done with the data, for the report
# Create individual dataframes for each list with explanations
df_na_question_topic <- data.frame(
RowNumber = na_question_topic,
Explanation = "NA question topic (Updated)"
)
df_wrong_topic <- data.frame(
RowNumber = troublesome_rows_wrong_topic,
Explanation = "Wrong question topic (Updated)"
)
df_non_numeric <- data.frame(
RowNumber = troublesome_rows_non_numeric,
Explanation = "Non-numeric value in average rating (Removed)"
)
df_na_question <- data.frame(
RowNumber = troublesome_rows_question,
Explanation = "NA question (Removed)"
)
# Combine all dataframes into one
data_cleaning_table <- rbind(df_na_question_topic, df_wrong_topic, df_non_numeric, df_na_question)
# Some rows needs to be removed, insufficient data to analyse
troublesome_rows_to_remove <- unique(c(troublesome_rows_non_numeric, troublesome_rows_question))
# Removing these troublesome rows
data <- data[-troublesome_rows_to_remove, ]
# Finally, there is some missing values for the other columns.
# However, it is still okay to use those rows for analysis.
# As these rows still contains information that is valuable.
# For instance, even if we don't know the sponsor organisation,
# we can still use the row to analyse virtual classes
################################################################################
#                     Cleaning up the environment
# Define the objects to keep
objects_to_keep <- c("data", "data_cleaning_table")
# Get a list of all objects in the environment
all_objects <- ls()
# Identify objects to remove (those not in the list of objects to keep)
objects_to_remove <- setdiff(all_objects, objects_to_keep)
# Remove the objects that are not in the keep list
rm(list = objects_to_remove)
rm(all_objects)
rm(objects_to_remove)
################################################################################
#   End of data cleaning
################################################################################
################################################################################
#   Data analysis
################################################################################
#########################
##   Online learning   ##
#########################
View(data)
unique(data$question)
unique(data$`average rating`)
unique(data$`question topic`)
unique(data$`course was virtual`)
unique(data$`sponsoring organisation`)
unique(data$date)
